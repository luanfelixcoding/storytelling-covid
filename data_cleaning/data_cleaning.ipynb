{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d5560b",
   "metadata": {},
   "source": [
    "### Importando Biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2e39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04735fad",
   "metadata": {},
   "source": [
    "### Convertendo a base de dados `.xlsx` para `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083339d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o arquivo .xlsx\n",
    "file_excel_path: str = r\"caminho_para_arquivo_xlsx\"\n",
    "df_excel = pd.read_excel(r\"seuarquivo.xlsx\")\n",
    "\n",
    "# Salva como .csv\n",
    "df_excel.to_csv(\"seuarquivo_convertido.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f46b6",
   "metadata": {},
   "source": [
    "### Lendo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e93248cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"rendimento_escolar_2020.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, skiprows=8)\n",
    "\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6809150",
   "metadata": {},
   "source": [
    "### Mudando os nomes das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "489e740d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ano', 'unidade_geografica', 'localizacao', 'dependencia_adm',\n",
       "       'total_aprovacao_FUND', 'tap_F14', 'tap_F04', 'tap_F58', 'tap_F00',\n",
       "       'tap_F01', 'tap_F02', 'tap_F03', 'tap_F05', 'tap_F06', 'tap_F07',\n",
       "       'tap_F08', 'total_aprovacao_EM', 'tap_M01', 'tap_M02', 'tap_M03',\n",
       "       'tap_M04', 'tap_MNS', 'total_reprovacao_FUND', 'tre_F14', 'tre_F04',\n",
       "       'tre_F58', 'tre_F00', 'tre_F01', 'tre_F02', 'tre_F03', 'tre_F05',\n",
       "       'tre_F06', 'tre_F07', 'tre_F08', 'total_reprovacao_EM', 'tre_M01',\n",
       "       'tre_M02', 'tre_M03', 'tre_M04', 'tre_MNS', 'total_abandono_FUND',\n",
       "       'tab_F14', 'tab_F04', 'tab_F58', 'tab_F00', 'tab_F01', 'tab_F02',\n",
       "       'tab_F03', 'tab_F05', 'tab_F06', 'tab_F07', 'tab_F08',\n",
       "       'total_abandono_EM', 'tab_M01', 'tab_M02', 'tab_M03', 'tab_M04',\n",
       "       'tab_MNS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={\n",
    "    \"ano\": \"ano\",\n",
    "    \"Unnamed: 1\": \"unidade_geografica\",\n",
    "    \"TIPOLOCA\": \"localizacao\",\n",
    "    \"DEPENDAD\": \"dependencia_adm\",\n",
    "    \"tap_FUN\": \"total_aprovacao_FUND\",\n",
    "    \"tap_MED\": \"total_aprovacao_EM\",\n",
    "    \"tre_FUN\": \"total_reprovacao_FUND\",\n",
    "    \"tre_MED\": \"total_reprovacao_EM\",\n",
    "    \"tab_FUN\": \"total_abandono_FUND\",\n",
    "    \"tab_MED\": \"total_abandono_EM\",\n",
    "}, inplace=True)\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e8e87",
   "metadata": {},
   "source": [
    "### Filtrando as Colunas necesssárias para um novo DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "262611d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ano unidade_geografica localizacao dependencia_adm total_aprovacao_FUND  \\\n",
      "0  2020             Brasil       Total           Total                 98.2   \n",
      "1  2020             Brasil      Urbana           Total                 98.2   \n",
      "2  2020             Brasil       Rural           Total                 98.1   \n",
      "3  2020             Brasil       Total         Federal                 99.2   \n",
      "4  2020             Brasil      Urbana         Federal                 99.2   \n",
      "\n",
      "  total_aprovacao_EM total_reprovacao_FUND total_reprovacao_EM  \\\n",
      "0                 95                   0.8                 2.7   \n",
      "1                 95                   0.8                 2.7   \n",
      "2                 95                   0.7                 2.6   \n",
      "3               88.2                   0.8                  10   \n",
      "4               89.2                   0.8                 9.1   \n",
      "\n",
      "  total_abandono_FUND total_abandono_EM  \n",
      "0                   1               2.3  \n",
      "1                   1               2.3  \n",
      "2                 1.2               2.4  \n",
      "3                   0               1.8  \n",
      "4                   0               1.7  \n"
     ]
    }
   ],
   "source": [
    "# df['tap_FUN'] # total aprovação FUND\n",
    "# df['tap_MED'] # total aprovação EM\n",
    "# df['tre_FUN'] # total reprovação FUND\n",
    "# df['tre_MED'] # total reprovacao EM\n",
    "# df['tab_FUN'] # total abandono FUND\n",
    "# df['tab_MED'] # total abandono MED\n",
    "\n",
    "# Selecionar apenas as colunas desejadas\n",
    "colunas_desejadas = [\n",
    "    'ano', 'unidade_geografica', 'localizacao', 'dependencia_adm',\n",
    "    'total_aprovacao_FUND', 'total_aprovacao_EM', 'total_reprovacao_FUND', \n",
    "    'total_reprovacao_EM', 'total_abandono_FUND', 'total_abandono_EM'\n",
    "]\n",
    "\n",
    "df_limpo = df[colunas_desejadas]\n",
    "\n",
    "# Visualizar as primeiras linhas\n",
    "print(df_limpo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bec99a8",
   "metadata": {},
   "source": [
    "### Valores somente do Brasil, sem ser de nenhuma região específica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b45955d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brasil = df_limpo[df_limpo[\"unidade_geografica\"] == \"Brasil\"]\n",
    "\n",
    "df_brasil.to_csv('rendimento_2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9bd9fc",
   "metadata": {},
   "source": [
    "### Imports e Caminhos(Paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc97d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a5b975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos (Paths)\n",
    "\n",
    "BASE_DIR = Path(\"C:/Users/INFORMATICO/Desktop/storytelling-covid/datasets\")\n",
    "RAW_DATA_DIR = BASE_DIR / \"raw_data\"\n",
    "CLEAN_DATA_DIR = BASE_DIR / \"clean_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae38d6",
   "metadata": {},
   "source": [
    "### Constantes de Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fa503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas desejadas e renomeadas\n",
    "COLUMNS_RENAME = {\n",
    "    \"ano\": \"ano\",\n",
    "    \"Unnamed: 1\": \"unidade_geografica\",\n",
    "    \"TIPOLOCA\": \"localizacao\",\n",
    "    \"DEPENDAD\": \"dependencia_adm\",\n",
    "    \"tap_FUN\": \"total_aprovacao_FUND\",\n",
    "    \"tap_MED\": \"total_aprovacao_EM\",\n",
    "    \"tre_FUN\": \"total_reprovacao_FUND\",\n",
    "    \"tre_MED\": \"total_reprovacao_EM\",\n",
    "    \"tab_FUN\": \"total_abandono_FUND\",\n",
    "    \"tab_MED\": \"total_abandono_EM\",\n",
    "}\n",
    "\n",
    "COLUNAS_DESEJADAS = list(COLUMNS_RENAME.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905b6bc",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "757ac516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def limpar_dataset_educacao_trabalho(path_csv: Path) -> pd.DataFrame:\\n    \"\"\"Exemplo de função para limpar dataset de educação e trabalho\"\"\"\\n    df = pd.read_csv(path_csv)\\n    # Exemplo genérico — personalizar conforme estrutura do dataset\\n    df = df.dropna(how=\"all\")  # Remove linhas totalmente vazias\\n    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\\n    output_path = CLEAN_DATA_DIR / \"educacao_trabalho_limpo.csv\"\\n    df.to_csv(output_path, index=False)\\n    print(f\"[✔] Dados de educação e trabalho limpos em: {output_path}\")\\n    return df'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def converter_excel_para_csv(arquivo_xlsx: Path, nome_csv_saida: str, ano: int) -> Path:\n",
    "    \"\"\"Converte um arquivo .xlsx em .csv\"\"\"\n",
    "    df = pd.read_excel(arquivo_xlsx)\n",
    "    csv_path = CLEAN_DATA_DIR / f\"rendimento_escolar/{ano}/{nome_csv_saida}\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"[✔] Arquivo convertido para CSV: {csv_path}\")\n",
    "    return csv_path\n",
    "\n",
    "\n",
    "def limpar_dataset_rendimento(path_csv: Path, ano: int, skiprows: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"Limpa o dataset de rendimento escolar e retorna apenas os dados do Brasil\"\"\"\n",
    "    df = pd.read_csv(path_csv, skiprows=skiprows)\n",
    "    df.rename(columns=COLUMNS_RENAME, inplace=True)\n",
    "    df = df[COLUNAS_DESEJADAS]\n",
    "    df_brasil = df[df[\"unidade_geografica\"] == \"Brasil\"]\n",
    "    output_path = CLEAN_DATA_DIR / f\"rendimento_brasil_{ano}.csv\"\n",
    "    df_brasil.to_csv(output_path, index=False)\n",
    "    print(f\"[✔] Dados limpos salvos em: {output_path}\")\n",
    "    return df_brasil\n",
    "\n",
    "\n",
    "'''def limpar_dataset_educacao_trabalho(path_csv: Path) -> pd.DataFrame:\n",
    "    \"\"\"Exemplo de função para limpar dataset de educação e trabalho\"\"\"\n",
    "    df = pd.read_csv(path_csv)\n",
    "    # Exemplo genérico — personalizar conforme estrutura do dataset\n",
    "    df = df.dropna(how=\"all\")  # Remove linhas totalmente vazias\n",
    "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    output_path = CLEAN_DATA_DIR / \"educacao_trabalho_limpo.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"[✔] Dados de educação e trabalho limpos em: {output_path}\")\n",
    "    return df'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1625bcc",
   "metadata": {},
   "source": [
    "### Arquivo Principal(Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2c2b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Arquivo convertido para CSV: C:\\Users\\INFORMATICO\\Desktop\\storytelling-covid\\datasets\\clean_data\\rendimento_escolar\\2022\\tx_rend_brasil_regioes_ufs_2022.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['ano', 'localizacao', 'dependencia_adm', 'total_aprovacao_FUND', 'total_aprovacao_EM', 'total_reprovacao_FUND', 'total_reprovacao_EM', 'total_abandono_FUND', 'total_abandono_EM'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# Etapa 2: Limpeza dos datasets de rendimento\u001b[39;00m\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# limpar_dataset_rendimento(CLEAN_DATA_DIR / \"rendimento_escolar/2020/tx_rend_brasil_regioes_ufs_2020.csv\", 2020)\u001b[39;00m\n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# limpar_dataset_rendimento(CLEAN_DATA_DIR / \"rendimento_escolar/2021/tx_rend_brasil_regioes_ufs_2021.csv\", 2021)\u001b[39;00m\n\u001b[32m     65\u001b[39m     limpar_dataset_rendimento(CLEAN_DATA_DIR / \u001b[33m\"\u001b[39m\u001b[33mrendimento_escolar/2022/tx_rend_brasil_regioes_ufs_2022.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2022\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     60\u001b[39m converter_excel_para_csv(RAW_DATA_DIR / \u001b[33m\"\u001b[39m\u001b[33mrendimento_escolar/2022/tx_rend_brasil_regioes_ufs_2022.xlsx\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtx_rend_brasil_regioes_ufs_2022.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2022\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Etapa 2: Limpeza dos datasets de rendimento\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# limpar_dataset_rendimento(CLEAN_DATA_DIR / \"rendimento_escolar/2020/tx_rend_brasil_regioes_ufs_2020.csv\", 2020)\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# limpar_dataset_rendimento(CLEAN_DATA_DIR / \"rendimento_escolar/2021/tx_rend_brasil_regioes_ufs_2021.csv\", 2021)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43mlimpar_dataset_rendimento\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCLEAN_DATA_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrendimento_escolar/2022/tx_rend_brasil_regioes_ufs_2022.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2022\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mlimpar_dataset_rendimento\u001b[39m\u001b[34m(path_csv, ano, skiprows)\u001b[39m\n\u001b[32m     34\u001b[39m df = pd.read_csv(path_csv, skiprows=skiprows)\n\u001b[32m     35\u001b[39m df.rename(columns=COLUMNS_RENAME, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCOLUNAS_DESEJADAS\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     37\u001b[39m df_brasil = df[df[\u001b[33m\"\u001b[39m\u001b[33munidade_geografica\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mBrasil\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     38\u001b[39m output_path = CLEAN_DATA_DIR / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrendimento_brasil_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mano\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\INFORMATICO\\Desktop\\storytelling-covid\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\INFORMATICO\\Desktop\\storytelling-covid\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\INFORMATICO\\Desktop\\storytelling-covid\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['ano', 'localizacao', 'dependencia_adm', 'total_aprovacao_FUND', 'total_aprovacao_EM', 'total_reprovacao_FUND', 'total_reprovacao_EM', 'total_abandono_FUND', 'total_abandono_EM'] not in index\""
     ]
    }
   ],
   "source": [
    "# Caminhos (Paths)\n",
    "\n",
    "BASE_DIR = Path(\"C:/Users/INFORMATICO/Desktop/storytelling-covid/datasets\")\n",
    "RAW_DATA_DIR = BASE_DIR / \"raw_data\"\n",
    "CLEAN_DATA_DIR = BASE_DIR / \"clean_data\"\n",
    "\n",
    "# Colunas desejadas e renomeadas\n",
    "COLUMNS_RENAME = {\n",
    "    \"ano\": \"ano\",\n",
    "    \"Unnamed: 1\": \"unidade_geografica\",\n",
    "    \"TIPOLOCA\": \"localizacao\",\n",
    "    \"DEPENDAD\": \"dependencia_adm\",\n",
    "    \"tap_FUN\": \"total_aprovacao_FUND\",\n",
    "    \"tap_MED\": \"total_aprovacao_EM\",\n",
    "    \"tre_FUN\": \"total_reprovacao_FUND\",\n",
    "    \"tre_MED\": \"total_reprovacao_EM\",\n",
    "    \"tab_FUN\": \"total_abandono_FUND\",\n",
    "    \"tab_MED\": \"total_abandono_EM\",\n",
    "}\n",
    "\n",
    "COLUNAS_DESEJADAS = list(COLUMNS_RENAME.values())\n",
    "\n",
    "def converter_excel_para_csv(arquivo_xlsx: Path, nome_csv_saida: str, ano: int) -> Path:\n",
    "    \"\"\"Converte um arquivo .xlsx em .csv\"\"\"\n",
    "    df = pd.read_excel(arquivo_xlsx)\n",
    "    csv_path = CLEAN_DATA_DIR / f\"rendimento_escolar/{ano}/{nome_csv_saida}\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"[✔] Arquivo convertido para CSV: {csv_path}\")\n",
    "    return csv_path\n",
    "\n",
    "\n",
    "def limpar_dataset_rendimento(path_csv: Path, ano: int, skiprows: int = 7) -> pd.DataFrame:\n",
    "    \"\"\"Limpa o dataset de rendimento escolar e retorna apenas os dados do Brasil\"\"\"\n",
    "    df = pd.read_csv(path_csv, skiprows=skiprows)\n",
    "    df.rename(columns=COLUMNS_RENAME, inplace=True)\n",
    "    df = df[COLUNAS_DESEJADAS]\n",
    "    df_brasil = df[df[\"unidade_geografica\"] == \"Brasil\"]\n",
    "    output_path = CLEAN_DATA_DIR / f\"rendimento_brasil_{ano}.csv\"\n",
    "    df_brasil.to_csv(output_path, index=False)\n",
    "    print(f\"[✔] Dados limpos salvos em: {output_path}\")\n",
    "    return df_brasil\n",
    "\n",
    "\n",
    "'''def limpar_dataset_educacao_trabalho(path_csv: Path) -> pd.DataFrame:\n",
    "    \"\"\"Exemplo de função para limpar dataset de educação e trabalho\"\"\"\n",
    "    df = pd.read_csv(path_csv)\n",
    "    # Exemplo genérico — personalizar conforme estrutura do dataset\n",
    "    df = df.dropna(how=\"all\")  # Remove linhas totalmente vazias\n",
    "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    output_path = CLEAN_DATA_DIR / \"educacao_trabalho_limpo.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"[✔] Dados de educação e trabalho limpos em: {output_path}\")\n",
    "    return df'''\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Etapa 1: Converter arquivos .xlsx se necessário\n",
    "    # converter_excel_para_csv(RAW_DATA_DIR / \"rendimento_escolar/2020/tx_rend_brasil_regioes_ufs_2020.xlsx\", \"tx_rend_brasil_regioes_ufs_2020.csv\", 2020)\n",
    "    # converter_excel_para_csv(RAW_DATA_DIR / \"rendimento_escolar/2021/tx_rend_brasil_regioes_ufs_2021.xlsx\", \"tx_rend_brasil_regioes_ufs_2021.csv\", 2021)\n",
    "    converter_excel_para_csv(RAW_DATA_DIR / \"rendimento_escolar/2022/tx_rend_brasil_regioes_ufs_2022.xlsx\", \"tx_rend_brasil_regioes_ufs_2022.csv\", 2022)\n",
    "\n",
    "    # Etapa 2: Limpeza dos datasets de rendimento\n",
    "    # limpar_dataset_rendimento(CLEAN_DATA_DIR / \"rendimento_escolar/2020/tx_rend_brasil_regioes_ufs_2020.csv\", 2020)\n",
    "    # limpar_dataset_rendimento(CLEAN_DATA_DIR / \"rendimento_escolar/2021/tx_rend_brasil_regioes_ufs_2021.csv\", 2021)\n",
    "    limpar_dataset_rendimento(CLEAN_DATA_DIR / \"rendimento_escolar/2022/tx_rend_brasil_regioes_ufs_2022.csv\", 2022)\n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107771d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
